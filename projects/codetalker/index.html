<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="">
  <meta name="keywords" content="Speech-driven, 3D facial animation, codebook, discrete motion prior">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CodeTalker</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">CodeTalker: Speech-Driven 3D Facial Animation with Discrete Motion Prior</h1>
          <div class="column is-full_width">
            <h2 class="title is-4">CVPR 2023</h2>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://doubiiu.github.io/">Jinbo Xing</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://menghanxia.github.io/">Menghan Xia</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://julianjuaner.github.io/">Yuechen Zhang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://vinthony.github.io/academic/">Xiaodong Cun</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://juewang725.github.io/">Jue Wang</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.cse.cuhk.edu.hk/~ttwong/myself.html">Tien-Tsin Wong</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>The Chinese University of Hong Kong,</span>
            <span class="author-block"><sup>2</sup>Tencent AI Lab</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2301.02379"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="#teaser"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/Doubiiu/CodeTalker"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://colab.research.google.com/github/Doubiiu/CodeTalker/blob/main/demo.ipynb"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Online demo</span>
                  </a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay loop controls playsinline height="100%">
        <source src="./static/videos/demo_video_arxiv.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <strong>CodeTalker</strong> can synthesize vivid 3D facial animations (mesh sequences) given audio snippets.
      </h2>
    </div>
  </div>
</section>





<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Speech-driven 3D facial animation has been widely studied, yet there is still a gap to 
            achieving realism and vividness due to the highly ill-posed nature and scarcity of audio-visual data.

            Existing works typically formulate the cross-modal mapping into a regression task, 
            which suffers from the regression-to-mean problem leading to over-smoothed facial motions.

            In this paper, we propose to cast speech-driven facial animation as a code query task
             in a finite proxy space of the learned codebook, which effectively promotes the vividness
              of the generated motions by reducing the cross-modal mapping uncertainty.

            The codebook is learned by self-reconstruction over real facial motions and thus embedded
             with realistic facial motion priors.

            Over the discrete motion space, a temporal autoregressive model is employed to sequentially
             synthesize facial motions from the input speech signal, which guarantees lip-sync as well as
              plausible facial expressions. We demonstrate that our approach outperforms current state-of-the-art
               methods both qualitatively and quantitatively. Also, a user study further justifies our superiority
                in perceptual quality.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
<!-- Method. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method</h2>

        <!-- Discrete Motion Prior Learning. -->
        <h3 class="title is-4">Discrete Motion Prior Learning</h3>
        <div class="content has-text-justified">
          <p>
            CodeTalker first learns a discrete context-rich facial motion codebook by self-reconstruction
            learning over real facial motions.
          </p>
        </div>
          <div class="content has-text-centered">
            <img src="./static/images/codebook.png"
                style="width: 55%"/>
          </div>
        <br/>
        <!--/ Discrete Motion Prior Learning. -->

        <!-- Speech-Driven Motion Synthesis. -->
        <h3 class="title is-4">Speech-Driven Motion Synthesis</h3>
        <div class="content has-text-justified">
          <p>
            It then autoregressively synthesize facial motions through code query conditioned on
            both the speech signals and past motions.
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="./static/images/speech-to-motion.png"
              style="width: 100%"/>
        </div>
        <!--/ Speech-Driven Motion Synthesis. -->

      </div>
    </div>
  </div>
</section>  
<!--/ Method. -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Comparison</h2>

        <div class="content has-text-justified">
          <p>
            Visual comparisons of sampled facial motions animated by different methods on
            VOCA (left) and BIWI (right) dataset. The upper partition shows the facial 
            animation conditioned on different speech parts, while the lower depicts the 
            temporal statistics (mean and standard deviation) of adjacent-frame motion variations within a sequence.
          </p>
        </div>

        <div class="content has-text-centered">
          <img src="./static/images/comparison.png"
              style="width: 100%"/>
        </div>

      </div>
    </div>
  </div>
</section>  


<!-- <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Works</h2>

        <div class="content has-text-justified">
          <ul>

          </ul>
        </div>

      </div>
    </div>
  </div>
</section>   
-->


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{xing2023codetalker,
  author    = {Xing, Jinbo and Xia, Menghan and Zhang, Yuechen and Cun, Xiaodong and Wang, Jue and Wong, Tien-Tsin},
  title     = {CodeTalker: Speech-Driven 3D Facial Animation with Discrete Motion Prior},
  journal   = {arXiv preprint arXiv:2301.02379},
  year      = {2023},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website source code based on the <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> project page.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
