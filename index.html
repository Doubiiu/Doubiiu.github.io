<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jinbo Xing</title>
  
  <meta name="author" content="Jinbo Xing">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" type="image/x-icon" href="images/icon.svg">
</head>

<body>
  <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jinbo Xing</name>
              </p>
              <p>
                I am currently a final-year Ph.D student in the 
                <a href="http://www.cse.cuhk.edu.hk/">CSE Department</a>, 
                <a href="http://www.cuhk.edu.hk/">CUHK</a>, 
                supervised by <a href="https://www.cse.cuhk.edu.hk/~ttwong/myself.html">Prof. Tien-Tsin WONG</a> and <a href="https://www.cse.cuhk.edu.hk/~cwfu/">Prof. Chi-Wing FU</a>.
              </p>
              <p>
                Previously, I received my B.Sc. (1st class honor & <a href="https://www.erg.cuhk.edu.hk/erg/Elite">ELITE Stream</a>) and M.Sc. degrees in Computer Science at CUHK in 2020 and 2021 respectively.
              </p>
              <p>
                I'm focusing on GenAI for video & Multi-modal Content Understanding & Generation.
              </p>
              <p>
		    <img src="images/logo.png" 
		         alt="Tongyi Wan Team Logo" 
		         style="height: 1em; vertical-align: middle; margin-right: 0.3em;">
		    <b>[Tongyi Wan Team] We are actively looking for research interns to work on cutting-edge research topics (Video Generation/MLLM/...).</b> Please reach out to me at JinboXING[at]link[dot]cuhk[dot]edu[dot]hk.
	      </p>


              <p style="text-align:center">
                <a href="mailto:jbxing@cse.cuhk.edu.hk">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=ZB0gLU0AAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/Doubiiu">Github</a> &nbsp/&nbsp
                <a href="https://www.researchgate.net/profile/Jinbo_Xing2">ResearchGate</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/jinbo-xing-3158821a1/">LinkedIn</a> &nbsp/&nbsp
                <a href="data/Resume.pdf">X</a> &nbsp/&nbsp
		<a href="data/Resume.pdf">CV</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/photo_personal_page.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/photo_personal_page.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research Works</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



          <tr onmouseout="tc_stop()" onmouseover="tc_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id="tc_image" style="display: inline;"> 
                  <img src='images/tooncrafter/tc.png' alt="after for CodeTalker" width="320" height="180">
                </div>
                <img src='images/tooncrafter/tc.gif' alt="after for CodeTalker" width="320" height="180">

              </div>
              <script type="text/javascript">
                function tc_start() {
                  document.getElementById('tc_image').style.opacity = "1";
                }

                function tc_stop() {
                  document.getElementById('tc_image').style.opacity = "0";
                }
                tc_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <b>
                <papertitle>ToonCrafter: Generative Cartoon Interpolation</papertitle>
              </b>
              <br>
              
              <strong>Jinbo Xing</strong>,
              <a href="https://github.com/hyliu">Hanyuan Liu</a>,
              <a href="https://menghanxia.github.io/">Menghan Xia</a>,
              <a href="https://yzhang2016.github.io/">Yong Zhang</a>,
              <a href="https://xinntao.github.io/">Xintao Wang</a>,
              <a href="https://scholar.google.com/citations?hl=en&user=4oXBp9UAAAAJ&view_op=list_works&sortby=pubdate">Ying Shan</a>,
              <a href="https://www.cse.cuhk.edu.hk/~ttwong/myself.html">Tien-Tsin Wong</a>
              <br>
              <em><b>SIGGRAPH Asia</b></em>, 2024, <b>Journal Track</b> (selected in <a href="https://www.youtube.com/watch?v=hUktDm6WU6w">Technical Papers Trailer</a>)
              <p> 
		<a href="https://doi.org/10.1145/3687761">Paper</a> 
                &nbsp/&nbsp <a href="https://arxiv.org/abs/2405.17933">arXiv</a> 
                &nbsp/&nbsp <a href="https://doubiiu.github.io/projects/ToonCrafter/">Project</a> 
                &nbsp/&nbsp <a href="https://huggingface.co/spaces/Doubiiu/tooncrafter">Demo</a> 
                &nbsp/&nbsp <a href="https://github.com/Doubiiu/ToonCrafter">Code</a> <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/Doubiiu/ToonCrafter?style=social"> 
              </p>
              <p>
                Taming large-scale video diffusion models for generative cartoon interpolation.
              </p>
            </td>
          </tr>


          <tr onmouseout="dc_stop()" onmouseover="dc_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id="dc_image" style="display: inline;"> 
                  <img src='images/dynamicrafter/dynamicrafter_cover.png' alt="after for CodeTalker" width="320" height="180">
                </div>
                <img src='images/dynamicrafter/dynamicrafter_cover.gif' alt="after for CodeTalker" width="320" height="180">

              </div>
              <script type="text/javascript">
                function dc_start() {
                  document.getElementById('dc_image').style.opacity = "1";
                }

                function dc_stop() {
                  document.getElementById('dc_image').style.opacity = "0";
                }
                dc_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <b>
                <papertitle>DynamiCrafter: Animating Open-domain Images with Video Diffusion Priors</papertitle>
              </b>
              <br>
              
              <strong>Jinbo Xing</strong>,
              <a href="https://menghanxia.github.io/">Menghan Xia</a>,
              <a href="https://yzhang2016.github.io/">Yong Zhang</a>,
              <a href="#">Haoxin Chen</a>,
              <a href="#">Wangbo Yu</a>,
              <a href="https://github.com/hyliu">Hanyuan Liu</a>,
              <a href="#">Gongye Liu</a>,
              <a href="https://xinntao.github.io/">Xintao Wang</a>,
              <a href="https://scholar.google.com/citations?hl=en&user=4oXBp9UAAAAJ&view_op=list_works&sortby=pubdate">Ying Shan</a>,
              <a href="https://www.cse.cuhk.edu.hk/~ttwong/myself.html">Tien-Tsin Wong</a>
              <br>
              <em>European Conference on Computer Vision (<b>ECCV, Oral</b>)</em>, 2024
              <p> 
		<a href="https://link.springer.com/chapter/10.1007/978-3-031-72952-2_23">Paper</a> 
                &nbsp/&nbsp <a href="https://arxiv.org/abs/2310.12190">arXiv</a> 
                &nbsp/&nbsp <a href="https://doubiiu.github.io/projects/DynamiCrafter/">Project</a>
                &nbsp/&nbsp <a href="https://huggingface.co/spaces/Doubiiu/DynamiCrafter">Demo</a>  
                &nbsp/&nbsp <a href="https://github.com/Doubiiu/DynamiCrafter">Code</a> <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/Doubiiu/DynamiCrafter?style=social"> 
              </p>
              <p>
                An open-domain high-quality image-to-video foundation model.
              </p>
            </td>
          </tr>


          <tr onmouseout="viewc_stop()" onmouseover="viewc_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id="viewc_image" style="display: inline;"> 
                  <img src='images/viewcrafter/viewc.png' alt="after for CodeTalker" width="320" height="180">
                </div>
                <img src='images/viewcrafter/viewc.gif' alt="after for CodeTalker" width="320" height="180">

              </div>
              <script type="text/javascript">
                function viewc_start() {
                  document.getElementById('viewc_image').style.opacity = "1";
                }

                function viewc_stop() {
                  document.getElementById('viewc_image').style.opacity = "0";
                }
                viewc_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <b>
                <papertitle>ViewCrafter: Taming Video Diffusion Models for High-fidelity Novel View Synthesis</papertitle>
              </b>
              <br>
              
              <a href="https://scholar.google.com/citations?user=UOE8-qsAAAAJ&hl=zh-CN">Wangbo Yu*</a>,
              <strong>Jinbo Xing*</strong>,
              <a href="https://yuanli2333.github.io/">Li Yuan*</a>,
              <a href="https://wbhu.github.io/">Wenbo Hu</a>,
              <a href="https://xiaoyu258.github.io/">Xiaoyu Li</a>,
              <a href="#">Zhipeng Huang</a>,
              <a href="https://scholar.google.com/citations?user=qgdesEcAAAAJ&hl=en/">Xiangjun Gao</a>,
              <a href="https://www.cse.cuhk.edu.hk/~ttwong/myself.html">Tien-Tsin Wong</a>,
              <a href="https://scholar.google.com/citations?hl=en&user=4oXBp9UAAAAJ&view_op=list_works&sortby=pubdate">Ying Shan</a>,
              <a href="https://scholar.google.com/citations?user=fn6hJx0AAAAJ&hl=en">Yonghong Tian</a>
              <br>
              <em>arXiv preprint</em>, 2024
              <p> 
                <a href="https://arxiv.org/abs/2409.02048">arXiv</a> 
                &nbsp/&nbsp <a href="https://drexubery.github.io/ViewCrafter/">Project</a> 
                &nbsp/&nbsp <a href="https://huggingface.co/spaces/Doubiiu/ViewCrafter">Demo</a> 
                &nbsp/&nbsp <a href="https://github.com/Drexubery/ViewCrafter">Code</a> <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/Drexubery/ViewCrafter?style=social"> 
              </p>
              <p>
                Taming large-scale video diffusion models for high-fidelity novel view synthesis.
              </p>
            </td>
          </tr>


          <tr onmouseout="trajc_stop()" onmouseover="trajc_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id="trajc_image" style="display: inline;"> 
                  <img src='images/TrajectoryCrafter/cover_jinbo_webpage2.gif' alt="after for CodeTalker" width="320" height="180">
                </div>
                <img src='images/TrajectoryCrafter/cover_jinbo_webpage.gif' alt="after for CodeTalker" width="320" height="180">

              </div>
              <script type="text/javascript">
                function trajc_start() {
                  document.getElementById('trajc_image').style.opacity = "1";
                }

                function trajc_stop() {
                  document.getElementById('trajc_image').style.opacity = "0";
                }
                trajc_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <b>
                <papertitle>TrajectoryCrafter: Redirecting Camera Trajectory for Monocular Videos via Diffusion Models</papertitle>
              </b>
              <br>
              
              <a href="#">Mark YU</a>,
	      <a href="https://wbhu.github.io/">Wenbo Hu</a>,
              <strong>Jinbo Xing</strong>,
              <a href="https://scholar.google.com/citations?hl=en&user=4oXBp9UAAAAJ&view_op=list_works&sortby=pubdate">Ying Shan</a>
              <br>
              <em>arXiv preprint</em>, 2025
              <p> 
                <a href="https://arxiv.org/abs/2503.05638">arXiv</a> 
                &nbsp/&nbsp <a href="https://trajectorycrafter.github.io/">Project</a> 
                &nbsp/&nbsp <a href="https://huggingface.co/spaces/Doubiiu/TrajectoryCrafter">Demo</a> 
                &nbsp/&nbsp <a href="https://github.com/TrajectoryCrafter/TrajectoryCrafter">Code</a> <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/TrajectoryCrafter/TrajectoryCrafter?style=social"> 
              </p>
              <p>
                Generating high-fidelity novel views from casually captured monocular video, while also supporting exact pose control.
              </p>
            </td>
          </tr>

		

          <tr onmouseout="sc_stop()" onmouseover="sc_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id="sc_image" style="display: inline;"> 
                  <img src='images/stylecrafter/cover.gif' alt="after for CodeTalker" width="320" height="180">
                </div>
                <img src='images/stylecrafter/cover.gif' alt="after for CodeTalker" width="320" height="180">

              </div>
              <script type="text/javascript">
                function sc_start() {
                  document.getElementById('sc_image').style.opacity = "1";
                }

                function sc_stop() {
                  document.getElementById('sc_image').style.opacity = "0";
                }
                sc_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <b>
                <papertitle>StyleCrafter: Enhancing Stylized Text-to-Video Generation with Style Adapter</papertitle>
              </b>
              <br>
              
              <a href="https://github.com/GongyeLiu">Gongye Liu</a>,
              <a href="https://menghanxia.github.io/">Menghan Xia</a>,
              <a href="https://yzhang2016.github.io/">Yong Zhang</a>,
              <a href="#">Haoxin Chen</a>,
              <strong>Jinbo Xing</strong>,
              <a href="https://xinntao.github.io/">Xintao Wang</a>,
              <a href="https://scholar.google.com/citations?user=4gH3sxsAAAAJ&hl=zh-CN&oi=ao">Yujiu Yang</a>,
              <a href="https://scholar.google.com/citations?hl=en&user=4oXBp9UAAAAJ&view_op=list_works&sortby=pubdate">Ying Shan</a>
              <br>
              <em><b>SIGGRAPH Asia</b></em>, 2024, <b>Journal Track</b>
              <p> 
		<a href="https://doi.org/10.1145/3687975">Paper</a> 
                &nbsp/&nbsp <a href="https://arxiv.org/abs/2312.00330">arXiv</a> 
                &nbsp/&nbsp <a href="https://gongyeliu.github.io/StyleCrafter.github.io/">Project</a>
                &nbsp/&nbsp <a href="https://huggingface.co/spaces/liuhuohuo/StyleCrafter">Demo</a>  
                &nbsp/&nbsp <a href="https://github.com/GongyeLiu/StyleCrafter">Code</a> <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/GongyeLiu/StyleCrafter?style=social"> 
              </p>
              <p>
                Given a stylized image as reference, the model can generate images and videos with consistent styles based on text prompt.
              </p>
            </td>
          </tr>


          <tr onmouseout="vc_stop()" onmouseover="vc_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id="vc_image" style="display: inline;"> 
                  <img src='images/videocrafter/girl.gif' alt="after for CodeTalker" width="320" height="180">
                </div>
                <img src='images/videocrafter/girl.gif' alt="after for CodeTalker" width="320" height="180">

              </div>
              <script type="text/javascript">
                function vc_start() {
                  document.getElementById('vc_image').style.opacity = "1";
                }

                function vc_stop() {
                  document.getElementById('vc_image').style.opacity = "0";
                }
                vc_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <b>
                <papertitle>VideoCrafter1 : Open Diffusion Models for High-Quality Video Generation</papertitle>
              </b>
              <br>
              
              <a href="#">Haoxin Chen</a>,
              <a href="https://menghanxia.github.io/">Menghan Xia</a>,
              <a href="https://github.com/YingqingHe">Yingqing He</a>,
              <a href="https://yzhang2016.github.io/">Yong Zhang</a>,
              <a href="https://vinthony.github.io/academic/">Xiaodong Cun</a>,
              <a href="#">Shaoshu Yang</a>,
              <strong>Jinbo Xing</strong>,
              <a href="#">Yaofang Liu</a>,
              <a href="https://cqf.io/">Qifeng Chen</a>,
              <a href="https://xinntao.github.io/">Xintao Wang</a>,
              <a href="#">Chao Weng</a>,
              <a href="https://scholar.google.com/citations?hl=en&user=4oXBp9UAAAAJ&view_op=list_works&sortby=pubdate">Ying Shan</a>
              <br>
              <em>arXiv preprint</em>, 2023
              <p> 
                <a href="https://arxiv.org/abs/2310.19512">arXiv</a> 
                &nbsp/&nbsp <a href="https://ailab-cvc.github.io/videocrafter/">Project</a> 
                &nbsp/&nbsp <a href="https://github.com/AILab-CVC/VideoCrafter">Code</a> <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/AILab-CVC/VideoCrafter?style=social">
              </p>
              <p>
                An open-sourced foundational text-to-video and image-to-video diffusion model for high-quality video generation.
              </p>
            </td>
          </tr>



          <tr onmouseout="myv_stop()" onmouseover="myv_start()">
            <td style="padding:20px;width:35%;vertical-align:top;text-align:middle">
              <div class="one">
                <div class="two" id="myv_image" style="display: inline;"> 
                  <img src='images/makeyourvideo/demo1.gif' alt="after for CodeTalker" width="320" height="250">
                </div>
                <img src='images/makeyourvideo/demo2.gif' alt="after for CodeTalker" width="320" height="250">

              </div>
              <script type="text/javascript">
                function myv_start() {
                  document.getElementById('myv_image').style.opacity = "1";
                }

                function myv_stop() {
                  document.getElementById('myv_image').style.opacity = "0";
                }
                myv_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <b>
                <papertitle>Make-Your-Video: Customized Video Generation Using Textual and Structural Guidance</papertitle>
              </b>
              <br>
              
              <strong>Jinbo Xing</strong>,
              <a href="https://menghanxia.github.io/">Menghan Xia</a>,
              <a href="#">Yuxin Liu</a>,
              <a href="https://julianjuaner.github.io/">Yuechen Zhang</a>,
              <a href="https://yzhang2016.github.io/">Yong Zhang</a>,
              <a href="https://github.com/YingqingHe">Yingqing He</a>,
              <a href="https://github.com/hyliu">Hanyuan Liu</a>,
              <a href="#">Haoxin Chen</a>,
              <a href="https://vinthony.github.io/academic/">Xiaodong Cun</a>,
              <a href="https://xinntao.github.io/">Xintao Wang</a>,
              <a href="https://scholar.google.com/citations?hl=en&user=4oXBp9UAAAAJ&view_op=list_works&sortby=pubdate">Ying Shan</a>,
              <a href="https://www.cse.cuhk.edu.hk/~ttwong/myself.html">Tien-Tsin Wong</a>
              <br>
              <em>IEEE Transactions on Visualization and Computer Graphics (<b>TVCG</b>)</em>, 2025
              <p> 
		<a href="https://www.computer.org/csdl/journal/tg/2025/02/10436391/1UwVf2MBnby">Paper</a> 
                &nbsp/&nbsp <a href="https://arxiv.org/abs/2306.00943">arXiv</a> 
                &nbsp/&nbsp <a href="https://doubiiu.github.io/projects/Make-Your-Video/">Project</a> 
                &nbsp/&nbsp <a href="https://github.com/AILab-CVC/Make-Your-Video">Code</a> <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/AILab-CVC/Make-Your-Video?style=social">
              </p>
              <p>
                Given text description and video structure (depth), our approach can generate temporally coherent and high-fidelity videos. Its applications include dynamic 3d-scene-to-video creation, real-life scene to video, and video rerendering.
              </p>
            </td>
          </tr>


	  <tr onmouseout="ms_stop()" onmouseover="ms_start()">
            <td style="padding:20px;width:35%;vertical-align:top;text-align:middle">
              <div class="one">
                <div class="two" id="ms_image" style="display: inline;"> 
                  <img src='images/magicstick/demo1.gif' alt="after for CodeTalker" width="320" height="180">
                </div>
                <img src='images/magicstick/demo2.gif' alt="after for CodeTalker" width="320" height="180">

              </div>
              <script type="text/javascript">
                function ms_start() {
                  document.getElementById('ms_image').style.opacity = "1";
                }

                function ms_stop() {
                  document.getElementById('ms_image').style.opacity = "0";
                }
                ms_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <b>
                <papertitle>MagicStick: Controllable Video Editing via Control Handle Transformations</papertitle>
              </b>
              <br>
              
              
              <a href="https://mayuelala.github.io/">Yue Ma</a>,
              <a href="https://vinthony.github.io/academic/">Xiaodong Cun</a>,
              <a href="#">Sen Liang</a>,
              <strong>Jinbo Xing</strong>,
              <a href="https://github.com/YingqingHe">Yingqing He</a>,
              <a href="https://chenyangqiqi.github.io/">Chenyang Qi</a>,
              <a href="#">Siran Chen</a>,
              <a href="https://cqf.io/">Qifeng Chen</a>
              <br>
              <em>IEEE/CVF Winter Conference on Applications of Computer Vision (<b>WACV</b>)</em>, 2025
              <p> 
                <a href="https://arxiv.org/abs/2312.03047">arXiv</a> 
                &nbsp/&nbsp <a href="https://magic-stick-edit.github.io/">Project</a> 
                &nbsp/&nbsp <a href="https://github.com/mayuelala/FollowYourHandle">Code</a> <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/mayuelala/FollowYourHandle?style=social">
              </p>
              <p>
                MagicStick is a unified framework to modify video properties (e.g., shape, size, location, motion) leveraging the keyframe transformations on the extracted internal control signals.
              </p>
            </td>
          </tr>
		

          <tr onmouseout="rival_stop()" onmouseover="rival_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
              <div class="two" id="rival_image" style="display: inline;"> 
                <img src='images/rival/rival.png' alt="after for piggycolor" width="320" height="180">
              </div>
                <img src='images/rival/rival-default.png' alt="before for piggycolor" width="320" height="180">
              </div>
              <script type="text/javascript">
                function rival_start() {
                  document.getElementById('rival_image').style.opacity = "1";
                }

                function rival_stop() {
                  document.getElementById('rival_image').style.opacity = "0";
                }
                rival_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <b>
                <papertitle>RIVAL: Real-World Image Variation by Aligning Diffusion Inversion Chain</papertitle>
              </b>
              <br>
              
              <a href="https://julianjuaner.github.io/">Yuechen Zhang</a>,
              <strong>Jinbo Xing</strong>,
              <a href="https://appsrv.cse.cuhk.edu.hk/~ericlo/">Eric Lo</a>,
              <a href="https://jiaya.me/">Jiaya Jia</a>

              <br>
              <em>Neural Information Processing Systems (<b>NeurIPS, Spotlight</b>)</em>, 2023
              <p> 
                <a href="https://arxiv.org/abs/2305.18729">arXiv</a> 
                &nbsp/&nbsp <a href="https://rival-diff.github.io/">Project</a> 
                &nbsp/&nbsp <a href="https://github.com/julianjuaner/RIVAL/">Code</a> <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/julianjuaner/RIVAL?style=social">
              </p>
              <p>
                Given a real-world image, our proposed method can generate its semantic-aligned variants. The approach is compatible with customized image generation, inpainting, controllable image synthesis, style transfer, etc.
              </p>
            </td>
          </tr>          

          <tr onmouseout="aas_stop()" onmouseover="aas_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
              <div class="two" id="aas_image" style="display: inline;"> 
                <img src='images/animate-a-story/teaser.png' alt="after for piggycolor" width="320" height="180">
              </div>
                <img src='images/animate-a-story/teaser.png' alt="before for piggycolor" width="320" height="180">
              </div>
              <script type="text/javascript">
                function aas_start() {
                  document.getElementById('aas_image').style.opacity = "1";
                }

                function aas_stop() {
                  document.getElementById('aas_image').style.opacity = "0";
                }
                aas_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <b>
                <papertitle>Animate-A-Story: Storytelling with Retrieval-Augmented Video Generation</papertitle>
              </b>
              <br>
              
              <a href="https://github.com/YingqingHe">Yingqing He</a>,
              <a href="https://menghanxia.github.io/">Menghan Xia</a>,
              <a href="#">Haoxin Chen</a>,
              <a href="https://vinthony.github.io/academic/">Xiaodong Cun</a>,
              <a href="https://github.com/yuanygong">Yuan Gong</a>,
              <strong>Jinbo Xing</strong>,
              <a href="https://yzhang2016.github.io/">Yong Zhang</a>,
              <a href="https://xinntao.github.io/">Xintao Wang</a>,
              <a href="#">Chao Weng</a>,
              <a href="https://scholar.google.com/citations?hl=en&user=4oXBp9UAAAAJ&view_op=list_works&sortby=pubdate">Ying Shan</a>,
              <a href="https://cqf.io/">Qifeng Chen</a>
              <br>
              AI4VA <em>ECCV Workshop</em>, 2024
              <p> 
                <a href="https://arxiv.org/abs/2307.06940">arXiv</a> 
                &nbsp/&nbsp <a href="https://github.com/AILab-CVC/Animate-A-Story">Project</a> 
                &nbsp/&nbsp <a href="https://github.com/AILab-CVC/Animate-A-Story">Code</a> <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/AILab-CVC/Animate-A-Story?style=social">
              </p>
              <p>
                We utilize the abundance of existing video clips and synthesize a coherent storytelling video by customizing their appearances with given visual concepts.
              </p>
            </td>
          </tr>
          
          <tr onmouseout="piggycolorvideo_stop()" onmouseover="piggycolorvideo_start()">
            <td style="padding:20px;width:35%;vertical-align:middle;text-align:middle">
              <div class="one" style="display: inline;">
                <!-- <div class="two" id="pcv_image" style="display: inline;"> 
                  <video  width="320" height="180" muted autoplay loop>
                  <source src="images/piggycolor-video/teaser-h265.mp4" alt="Annimation for FVI" width="320"type="video/mp4">
                  </video>
                </div> -->
                <div class="two" id="pcv_image" style="display: inline;">
                  <img src='images/piggycolor-video/screen.jpg' alt="before for piggycolor" width="320" height="150">
                </div>
                <img src='images/piggycolor-video/screen.jpg' alt="before for piggycolor" width="320" height="150">
              </div>
              <script type="text/javascript">
                function piggycolorvideo_start() {
                  document.getElementById('pcv_image').style.opacity = "1";
                }

                function piggycolorvideo_stop() {
                  document.getElementById('pcv_image').style.opacity = "0";
                }
                piggycolorvideo_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <b>
                <papertitle>Video Colorization with Pre-trained Text-to-Image Diffusion Models</papertitle>
              </b>
              <br>
              
              <a href="https://hyliu.org/">Hanyuan Liu</a>,
              <a href="https://msxie92.github.io/">Minshan Xie</a>,
              <strong>Jinbo Xing</strong>,
              <a href="https://moeka.me/">Chengze Li</a>, 
              <a href="https://www.cse.cuhk.edu.hk/~ttwong/myself.html">Tien-Tsin Wong</a>
              <br>
              <em>arXiv preprint</em>, 2023
              <p> 
                <a href="https://arxiv.org/abs/2306.01732">arXiv</a> &nbsp/&nbsp
                <a href="https://colordiffuser.github.io/">Project</a> &nbsp/&nbsp
                <a href="https://github.com/hyliu/ColorDiffuser">Code</a>
              </p>
              <p>
                We present an effective video colorization method, an adaptation of a pre-trained text-to-image diffusion model for video colorization.
              </p>
            </td>
          </tr>	

          <tr onmouseout="piggycolor_stop()" onmouseover="piggycolor_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
              <div class="two" id="pc_image" style="display: inline;"> 
                <img src='images/piggycolor/color.png' alt="after for piggycolor" width="320" height="180">
              </div>
                <img src='images/piggycolor/color.png' alt="before for piggycolor" width="320" height="180">
              </div>
              <script type="text/javascript">
                function piggycolor_start() {
                  document.getElementById('pc_image').style.opacity = "1";
                }

                function piggycolor_stop() {
                  document.getElementById('pc_image').style.opacity = "0";
                }
                piggycolor_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <b>
                <papertitle>Improved Diffusion-based Image Colorization via Piggybacked Models</papertitle>
              </b>
              <br>
              
              <a href="https://hyliu.org/">Hanyuan Liu</a>,
              <strong>Jinbo Xing</strong>,
              <a href="https://msxie92.github.io/">Minshan Xie</a>, 
              <a href="https://moeka.me/">Chengze Li</a>, 
              <a href="https://www.cse.cuhk.edu.hk/~ttwong/myself.html">Tien-Tsin Wong</a>
              <br>
              <em>arXiv preprint</em>, 2023
              <p> 
                <a href="https://arxiv.org/abs/2304.11105">arXiv</a> &nbsp/&nbsp
                <a href="https://piggyback-color.github.io/">Project</a> &nbsp/&nbsp
                <a href="https://github.com/hyliu/piggyback-color">Code</a>
              </p>
              <p>
                We present a novel image colorization method, which leaverages the rich diffusion model prior. It takes text-based
                 image colorization to another semantic level.
              </p>
            </td>
          </tr>	


          <tr onmouseout="codetalker_stop()" onmouseover="codetalker_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
              <div class="two" id="ct_image" style="display: inline;"> 
                <img src='images/codetalker/person.gif' alt="after for CodeTalker" width="320" height="180">
              </div>
                <img src='images/codetalker/person.png' alt="before for codetalker" width="320" height="180">
              </div>
              <script type="text/javascript">
                function codetalker_start() {
                  document.getElementById('ct_image').style.opacity = "1";
                }

                function codetalker_stop() {
                  document.getElementById('ct_image').style.opacity = "0";
                }
                codetalker_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <b>
                <papertitle>CodeTalker: Speech-Driven 3D Facial Animation with Discrete Motion Prior</papertitle>
              </b>
              <br>
              <strong>Jinbo Xing</strong>,
              <a href="https://menghanxia.github.io/">Menghan Xia</a>, 
              <a href="https://julianjuaner.github.io/">Yuechen Zhang</a>, 
              <a href="https://vinthony.github.io/academic/">Xiaodong Cun</a>, 
              <a href="https://juewang725.github.io/">Jue Wang</a>,  
              <a href="https://www.cse.cuhk.edu.hk/~ttwong/myself.html">Tien-Tsin Wong</a>
              <br>
              <em>Computer Vision and Pattern Recognition (<b>CVPR</b>)</em>, 2023
              <p> 
                <a href="https://arxiv.org/abs/2301.02379">arXiv</a> &nbsp/&nbsp
                <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Xing_CodeTalker_Speech-Driven_3D_Facial_Animation_With_Discrete_Motion_Prior_CVPR_2023_paper.html">Paper</a> &nbsp/&nbsp
                <a href="./projects/codetalker/">Project</a> &nbsp/&nbsp
                <a href="https://colab.research.google.com/github/Doubiiu/CodeTalker/blob/main/demo.ipynb">Demo</a> &nbsp/&nbsp
                <a href="https://github.com/Doubiiu/CodeTalker">Code</a> <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/Doubiiu/CodeTalker?style=social">
              </p>
              <p>
                We minimize the over-smoothed facial expression using a learned discrete motion prior,
                 which means more dramatic and expressive facial motions with more accurate lip movements can be achieved.
              </p>
            </td>
          </tr>		

		  
          <tr onmouseout="refnpr_stop()" onmouseover="refnpr_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='refnpr_image'>
                  <img src='images/refnpr/refnpr.gif' alt="after for Ref-NPR" width="320" height="180">
                </div>
                <img src='images/refnpr/refnpr_cover.png' alt="before for Ref-NPR" width="320" height="180">
              </div>
              <script type="text/javascript">
                function refnpr_start() {
                  document.getElementById('refnpr_image').style.opacity = "1";
                }

                function refnpr_stop() {
                  document.getElementById('refnpr_image').style.opacity = "0";
                }
                refnpr_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <b>
                <papertitle>Ref-NPR: Reference-Based Non-Photorealistic Radiance Fields</papertitle>
              </b>
              <br>
              <a href="https://julianjuaner.github.io/">Yuechen Zhang</a>, 
              <a href="https://zxhezexin.com/">Zexin He</a>, <strong>Jinbo Xing</strong>, 
              <a href="https://appsrv.cse.cuhk.edu.hk/~xfyao/">Xufeng Yao</a>,
              <a href="https://jiaya.me/">Jiaya Jia</a>
              <br>
              <em>Computer Vision and Pattern Recognition (<b>CVPR</b>)</em>, 2023
              <p> 
                <a href="https://arxiv.org/abs/2212.02766">arXiv</a> &nbsp/&nbsp
                <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Zhang_Ref-NPR_Reference-Based_Non-Photorealistic_Radiance_Fields_for_Controllable_Scene_Stylization_CVPR_2023_paper.html">Paper</a> &nbsp/&nbsp
                <a href="https://ref-npr.github.io/">Project</a> &nbsp/&nbsp
                <a href="https://youtu.be/jnsnrTwVSBw">Video</a> &nbsp/&nbsp
                <a href="https://drive.google.com/drive/folders/1b6L250lrBrSxfKYPmDBHuY_EP9n7WKnA?usp=share_link">Data</a> &nbsp/&nbsp
                <a href="https://github.com/dvlab-research/Ref-NPR/">Code</a> <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/dvlab-research/Ref-NPR?style=social"> 
              </p>
              <p>
                We present a controllable scene stylization method utilizing radiance fields to stylize a 3D scene, with a single stylized 2D view taken as reference.
              </p>
            </td>
          </tr>		
          


          <tr onmouseout="aidn_stop()" onmouseover="aidn_start()">
            <td style="padding:20px;width:35%;vertical-align:middle;text-align:middle">
              <div class="one" style="display: inline;" >
                <div class="two" id="aidn_image" style="display: inline; opacity: 0"> 
                  <img src="images/AIDN/teaser.gif" alt="Annimation for AIDN" width="320" height="180">
                </div>
                <img src='images/AIDN/teaser_cover.png' alt="Cover Image for AIDN" width="320" ,="" height="180">
              </div>
              <script type="text/javascript">
                function aidn_start() {
                  document.getElementById('aidn_image').style.opacity = "1";
                  console.log('start')
                }

                function aidn_stop() {
                  document.getElementById('aidn_image').style.opacity = "0";
                  console.log('stop')
                }
                aidn_stop()
              </script>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <b>
                <papertitle>Scale-arbitrary Invertible Image Downscaling</papertitle>
              </b>
              <br>
              <strong>Jinbo Xing</strong>*, 
              <a href="https://wbhu.github.io/">Wenbo Hu*</a>, 
              <a href="https://menghanxia.github.io/">Menghan Xia</a>,
              <a href="https://www.cse.cuhk.edu.hk/~ttwong/myself.html">Tien-Tsin Wong</a>
              <br>
              <em>IEEE Transactions on Image Processing (<b>TIP</b>)</em>, 2023
              <p> 
                <!-- <a href="https://arxiv.org/abs/2201.12576">arXiv</a> &nbsp/&nbsp -->
                <a href="https://ieeexplore.ieee.org/document/10192538?denied=">Paper</a> &nbsp/&nbsp
                <a href="./projects/aidn/">Project</a> &nbsp/&nbsp
                <a href="https://github.com/Doubiiu/AIDN">Code</a> &nbsp/&nbsp
                <a href="./projects/aidn/compare.html">Interactive inspection</a>
              </p>
              <p>
                We present a scale-arbitrary invertible image downscaling network (AIDN) to natively downscale HR images with arbitrary scale factors. Meanwhile, the HR images could be restored with AIDN whenever necessary.
              </p>
            </td>
          </tr>

          <tr onmouseout="fvi_stop()" onmouseover="fvi_start()">
            <td style="padding:20px;width:35%;vertical-align:middle;text-align:middle">
              <div class="one" style="display: inline;" >
                <div class="two" id="fvi_image" style="display: inline;"> 
                  <video  width="320" height="180" muted autoplay loop>
                  <source src="images/FVI_CVM21/FVI.mp4" alt="Annimation for FVI" width="320" height="180" type="video/mp4">
                  </video>
                </div>
                <img src='images/FVI_CVM21/FVI_cover.png' alt="Cover Image for FVI" width="320" height="180">
              </div>
              <script type="text/javascript">
                function fvi_start() {
                  document.getElementById('fvi_image').style.opacity = "1";
                  console.log('start')
                }

                function fvi_stop() {
                  document.getElementById('fvi_image').style.opacity = "0";
                  console.log('stop')
                }
                fvi_stop()
              </script>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <b>
                <papertitle>Flow-aware Synthesis: A Generic Motion Model for Video Frame Interpolation</papertitle>
              </b>
              <br>
              <strong>Jinbo Xing</strong>*, 
              <a href="https://wbhu.github.io/">Wenbo Hu*</a>, 
              <a href="https://julianjuaner.github.io/">Yuechen Zhang</a>,
              <a href="https://www.cse.cuhk.edu.hk/~ttwong/myself.html">Tien-Tsin Wong</a>
              <br>
              <em>Computational Visual Media (<b>CVM</b>)</em>, 2021
              <p> 
                <a href="https://link.springer.com/article/10.1007/s41095-021-0208-x">Paper</a>
              </p>
              <p>
                We present a flow-aware multi-frame interpolation method to address the complicated non-linear motions in the real world.
              </p>
            </td>
          </tr> 





          <tr onmouseout="dstc9_stop()" onmouseover="dstc9_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dstc9_image'>
                  <img src='images/DSTC9_AAAIW21/aaai_dstc9.png' width="320"></div>
                <img src='images/DSTC9_AAAIW21/aaai_dstc9.png' width="320">
              </div>
              <script type="text/javascript">
                function dstc9_start() {
                  document.getElementById('dstc9_image').style.opacity = "1";
                }

                function dstc9_stop() {
                  document.getElementById('dstc9_image').style.opacity = "0";
                }
                dstc9_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <b>
                <papertitle>Unstructured Knowledge Access in Task-oriented Dialog Modeling using Language Inference, Knowledge Retrieval and Knowledge-Integrative Response Generation</papertitle>
              </b>
              <br>
              Mudit Chaudhary, Borislav Dzodzo, Sida Huang, Chun Hei Lo, Mingzhi Lyu, Lun Yiu Nie, <strong>Jinbo Xing</strong>, Tianhua Zhang, Xiaoying Zhang, Jingyan Zhou, Hong Cheng, Wai Lam, Helen Meng (All authors contribute equally)
              <br>
              <em>AAAI Conference on Artificial Intelligence Workshop Program (<b>AAAIW</b>), DSTC9</em>, 2021
              <p>
                <a href="https://arxiv.org/abs/2101.06066">arXiv</a> &nbsp/&nbsp 
                <a href="https://www1.se.cuhk.edu.hk/~hccl/publications/pub/zhou_AAAI2021.pdf">Paper</a> &nbsp/&nbsp
                <a href="https://github.com/muditchaudhary/CUHK-DSTC9">Code</a> &nbsp/&nbsp
                <a href="https://www.youtube.com/watch?v=LSMWKg1u5Ac">Paper Reading</a> &nbsp/&nbsp
                <a href="https://muditchaudhary.github.io/assets/documents/Poster_DSTC9_AAAI21.pdf">Poster</a>
              </p>
              <p>
                We propose a system capable of accessing unstructured knowledge for task-oriented dialog.
              </p>
            </td>
          </tr>	

        </tbody></table>

				
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Work Experiences</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="border-spacing:20px 0px;">
          <tbody>
            <tr>
              <td style="padding:20px 10px 20px 10px;width:40%;text-align:left">
                <b><a href="https://github.com/ali-vilab">Alibaba Tongyi Lab</a></b>
              </td>
              <td style="padding:0px;width:40%;text-align:left">
                Research Intern<br>
                <b>Mentor</b>: <a href="https://scholar.google.com/citations?user=8zksQb4AAAAJ&hl=zh-CN">Yu Liu</a>
              </td>
              <td style="padding:0px;width:20%;text-align:left">
                <strong>Mar. 2025 - Present</strong>
              </td>
            </tr>
            <tr>
              <td style="padding:20px 10px 20px 10px;width:40%;text-align:left">
                <b><a href="https://research.adobe.com/">Adobe Research</a></b>
              </td>
              <td style="padding:0px;width:40%;text-align:left">
                Research Scientist Intern<br>
                <b>Mentor</b>: <a href="https://mai-t-long.com/">Dr. Long Mai</a>
              </td>
              <td style="padding:0px;width:20%;text-align:left">
                <strong>Jul. 2024 - Jan. 2025</strong>
              </td>
            </tr>
            <tr>
              <td style="padding:10px;width:40%;text-align:left">
                <b><a href="https://ai.tencent.com/ailab/en/index">Tencent AI Lab</a></b>
              </td>
              <td style="padding:0px;width:40%;text-align:left">
                Research Intern<br>
                <b>Mentor</b>: <a href="https://menghanxia.github.io/">Dr. Menghan Xia</a>
              </td>
              <td style="padding:0px;width:20%;text-align:left">
                <strong>Jun. 2022 - Jul. 2024</strong>
              </td>
            </tr>
            <tr>
              <td style="padding:10px;width:40%;text-align:left">
                <b><a href="https://www.bdda.cuhk.edu.hk/">Stanley Ho Big Data Decision Analytics Research Centre, CUHK</a></b>
              </td>
              <td style="padding:0px;width:40%;text-align:left">
                Research Assistant<br>
                <b>Supervisor</b>: <a href="https://www.se.cuhk.edu.hk/people/academic-staff/prof-meng-mei-ling-helen/">Prof. Helen Meng</a>
              </td>
              <td style="padding:0px;width:20%;text-align:left">
                <strong>May 2020 - Aug. 2021</strong>
              </td>
            </tr>


            <tr>
              <td style="padding:10px;width:40%;text-align:left">
                <b><a href="http://www.ee.cuhk.edu.hk/en-gb/">Electronic Engineering Dept., CUHK</a></b>
              </td>
              <td style="padding:0px;width:40%;text-align:left">
                Summer Research Intern<br>
                <b>Supervisor</b>: <a href="https://www.ee.cuhk.edu.hk/en-gb/people/academic-staff/professors/prof-ni-zhao">Prof. Ni Zhao</a>
              </td>
              <td style="padding:0px;width:20%;text-align:left">
                <strong>May 2018 - Jul. 2018</strong>
              </td>
            </tr>

          </tbody>
        </table>

					
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <heading>Awards</heading>
              </td>
            </tr>
          </tbody></table>
          <ul>
            <li>
              <p>
                Postgraduate Studentship
              </p>
            </li>
            <li>
              <p>
                Distinguished Academic Performance Scholarship of MSc Programme
              </p>
            </li>
            <li>
              <p>
                ELITE Stream Student Scholarship (2018, 2019)
              </p>
            </li>
            <li>
              <p>
                Computer Science scholarship
              </p>
            </li>
            <li>
              <p>
                Dean's List of Faculty of Engineering (2016, 2019, 2020)
              </p>
            </li>
            <li>
              <p>
                Full Scholarship for Undergraduate Students (Mainland)
              </p>
            </li>
          </ul>

 <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <heading>Invited Talks</heading>
              </td>
            </tr>
          </tbody></table>
          <ul>
            <li>
              <p>
                Feb.2025 "<i>Unified Motion Control for Image-to-Video Generation</i>" at <a href="https://blackforestlabs.ai/">Black Forest Labs</a> (BFL).
              </p>
            </li>
	    <li>
	      <p>
                Jun.2024 "<i>Controllable Video Generation</i>" at <a href="https://www.huaweicloud.com/intl/en-us/">Huawei</a>.
              </p>
            </li>
          </ul>

	      
            <!-- Teaching part -->
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tbody>
              <tr>
                <td>
                  <heading>Teaching</heading>
                </td>
              </tr>
              </tbody>
            </table>

            <table style="border-spacing:10px 0px;">
              <tbody>
              <tr>
                <td style="padding:10px;width:40%;text-align:left">
                  2023-2024&nbsp;&nbsp;	Spring	&nbsp;&nbsp; Computational Imaging and Vision (CSCI 3290)
                </td>
              <tr>
              <tr>
                <td style="padding:10px;width:40%;text-align:left">
                  2023-2024&nbsp;&nbsp;	Fall	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Advanced GPU Programming (CSCI 5390)
                </td>
              <tr>
              <tr>
                <td style="padding:10px;width:40%;text-align:left">
                  2022-2023&nbsp;&nbsp;	Spring	&nbsp;&nbsp; Introduction to Multimedia Systems (CSCI 3280)
                </td>
              <tr>
              <tr>
                <td style="padding:10px;width:40%;text-align:left">
                  2021-2022&nbsp;&nbsp;	Spring	&nbsp;&nbsp; Introduction to Multimedia Systems (CSCI 3280)
                </td>
              <tr>
              <tr>
                <td style="padding:10px;width:40%;text-align:left">
                  2021-2022&nbsp;&nbsp;	Fall &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	Problem Solving by Programming        (ENGG 1110)
                </td>
              <tr>
              <tr>
                <td style="padding:10px;width:40%;text-align:left">
                  2021-2022&nbsp;&nbsp;	Fall &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	Computer Game Software Production     (CMSC 5727)
                </td>
              <tr>
              </tbody>
            </table>

            <!-- Reviewer part-->
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
              <tr>
                <td>
                  <heading>Academic Services</heading>
                </td>
              </tr>
            </tbody></table>
            <ul>
              <li>
                <p>
                  Journal Review:
                  <br>
		  IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)
		  <br>
                  IEEE Transactions on Visualization and Computer Graphics (TVCG)
                  <br>
                  International Journal of Computer Vision (IJCV)
                  <br>
                  ACM Computing Surveys (CSUR)
                  <br>
                  IEEE Transactions on Multimedia (TMM)
                  <br>
                  The Visual Computer Journal (TVCJ)
                </p>
                
              </li>
            </ul>
            <ul>
              <li>
                <p>
                  Conference Review:
                  <br>
                  ECCV 2024, MM 2024, SIGGRAPH Asia 2024 <br>
		  ICLR 2025, CVPR 2025, SIGGRAPH 2025, ICCV 2025
                </p>
                
              </li>
            </ul>
            <!-- Misc part -->
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tbody>
              <tr>
                <td>
                  <heading>Misc</heading>
                </td>
              </tr>
              </tbody>
            </table>

            <table style="border-spacing:10px 0px;">
              <tbody>
              
              <tr>
                <td style="padding:10px;width:40%;text-align:left">
                  <img src='images/misc_camera.svg' width="20" ,="" height="20">&nbsp; &nbsp; I am a keen amateur photographer.
                </td>
              <tr>
                <tr>
                  <td style="padding:10px;width:40%;text-align:left">
                    <img src='images/misc_game.svg' width="20" ,="" height="20">&nbsp; &nbsp; A lover of League of Legends and Apex Legends (Best rank in Diamond).
                  </td>
                <tr>
              </tbody>
            </table>

            <!-- statistics -->
            <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tbody>
              <tr>
                <td>
                  <div id="clustrmaps-widget" style="width:50%"></div>
                  <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=cbR1z_qrHJJ5O2sTjvlJegefahAFrqE2oO-JD_KJPZ4&cl=ffffff&w=a"></script>
                  </div>  
                </td>
              </tr>
              </tbody>
            </table> -->
            <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=300&t=tt&d=cbR1z_qrHJJ5O2sTjvlJegefahAFrqE2oO-JD_KJPZ4&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080'></script>


            

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Last updated: March 2025
                <br>
                Web page design credit to <a href="https://jonbarron.info" style="font-size: 14px">Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>

